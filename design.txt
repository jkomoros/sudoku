dokugen must be able to solve Sudoku itself to be able to generate them.

A simple BFS of statespace on constraints should be fastest. But to get difficulty, we'll need to solve as a human does.

We'll have a fastSolve, which uses a constrained BFS, and a humanSolve, which proceeds knowing a grid can be solved and returns a difficulty.

Grids are passed back and forth over channels. They should be easily serializable and small whenever possible, but still be fast for common operations. You may read and write to them only if you have a ref, and you can only get a ref via a channel.


Grid {
	data string
	cells Cell[DIM * DIM]
}

TODO:

* Consider factoring out Rand methods to use a passthrough so we can test reasonably by setting a seed.

* Investigate why using the finite queue isn't making a big dent in Fill() performance.
* Reduce memory usage in cell: row, col, block are rarely asked for so can be derived?

* There's a leak somewhere in solve or fill. If you fill 500000 grids it runs out of memory.

* Some way to quickly copy queues and then enforce that all gets come from a copy; this will be useful for solver techniques which require a clean queue.
	* Queues have Getters that each consume the underlying data individually. Each queue has an insertionCounter variable that is updated whenever an insert happens. Each getter remembers the insertNumber it is keyed to; if it ever changes it throw out its work and starts again (keeping its ignoreMap the same). Each getter has an ignoreMap that it uses to ignore items it has already seen. Each time it switches to a new bucket it makes a copy of the bucket that has no holes and no nils an is randomized. It then hands off items from that bucket.

* Solve performance ideas
	* At each level, with some randomness (ideally weighted), diverge from DFS by changing which one we dive into and spin off the rest of the work items.

* Grid should suppot copy operations and have copy-on-write semantics with shared cells.
	* This is hard.
	* Grids can have parents. If they do, they are a "sparse grid".
		* No, should be a SparseGrid with a *Grid member.
		* SparseGrid has a Cell() method that looks in its cache. if it doesn't exist, looks to parent for one.
	* SparseCell is soemthing that looks like a cell but actually is a wrapper around one with a pointer back to the sparseGrid it's from.
		* Sparsecells have their own trapping of any modifiying calls that then call back to the sparseGrid (they know which it is) with the new cell itself to put in the cache. Then the SparseCell can be thrown away.
	* Simplest (no caching): Whenever you want a cell, you call grid.Cell(), which sees if it has one, otherwise returns one from another cell.

* Rate sudokus based on experienced difficulty. (See http://www.longwood.edu/assets/mathematics/Team2975_ProblemB.pdf)
	* Also: http://www.sudokuwiki.org/Sudoku_Creation_and_Grading.pdf
	* Also: http://zhangroup.aporc.org/images/files/Paper_3485.pdf
	* Signals:
		* Number of steps
		* Steps * normalized difficulty rating of each step
		* Weight of hardest technique (or index cutoff of highest technique)
		* Avergae weight of difficulties
	* Should difficulties go up exponentionally? A technique that requires no candidate marking is WAY, WAY easier than one that requires multiple leaps of logic.

* Human solve: Is it worth it to do nakedSingles based on row/col/block as well? Those are obvious in different ways.
* Human solve: Implement more solve tehcniques described at http://www.sadmansoftware.com/sudoku/solvingtechniques.htm. Technqiues I've skipped so far:
	* NakedQuad{Row,Col}. This now trivial given Subset logic. NEXT STEP
	* BlockBlock interactions

* Analysis: Spot check the results of the new markov difficulty grader to see if they intuitively make sense.
* Analysis: Run our difficulty grader on the real puzzles and see how well it fits with user perceived difficulty.
* Analysis: Throw out outliers for each individual user.
* Analysis: Throw out users who don't have a full range of difficulties in their history.
* Analysis: Build in plotting
* Analysis: Check in a sample solves_data and puzzles_data
* Analysis: Seriously refactor the monster (and confusing!) manin method).

* Investigate making better grids (fewer clues / more symmetry)

* Make it so NewGrid grabs a grid from grid cache if possible.
	* Actually call grid.Done() when we're done
	* We tried to do this but got CRAZY errors, which are hard to track down. Turns out that there is some possibility for slippage in grids, somehow. Need to solve that.
* When generating grids, at every step check the difficulty. If it's above the target, go back to the most recent known good difficulty and return that.

* When generating grids, keep a temporary directory of sdk files representing puzzles generated but not vended. When asked for a new puzzle, we first see if we have any in the unvended list that are appropriate difficulty.

* Test the Description string of each solve step

* Create a way to print out a solve walkthrough

* Use machine learning to help us set the constants for difficulty correctly

* Does our use of the Rand convenience funcs in different go routines cause performance problems? (http://stackoverflow.com/questions/14298523/why-does-adding-concurrency-slow-down-this-golang-code)
	* In any case we want to be able to test randomness.

* Make it so the docs generated from dokugen are all useful.

* REdo of threaded solving
	* Why is performance so slow?

* Add an interactive mode to the command line tool.

* Fix races with go test -race.

* Test the main app (partially there... just need to minimize randomness now)

* If HumanSolve gets stuck, it should do a guess as a last resort.


* Make it so if any technique takes too long and we already have some answers, we move ahead anyway.

* Move all of the puzzle constants in tests into SDK files

* Use gofmt to replace all instances of t.Log(a) t.Fail() with t.Error.

* Running `go run main.go -s ../puzzles/test/harddifficulty.sdk -w` results in a panic.

* The difficulties we get when generating puzzles from app are absurdly low (even 0 sometimes!)



